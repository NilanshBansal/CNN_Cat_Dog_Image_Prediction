{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "f032921ad10366a3068cbe3734055d58e97826a5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras packages\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "1e6b60fa58e1872115a0e42783646368c5231c52"
   },
   "outputs": [],
   "source": [
    "# Initialising the CNN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "9cbee6203304a7af3dbf531819eed89d00144f08"
   },
   "outputs": [],
   "source": [
    "# Step-1 Convolution\n",
    "classifier.add(Conv2D(32,(3,3),input_shape=(64,64,3), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "a114fcf4fb4afe7c2433e88931eeb37816d27ae2"
   },
   "outputs": [],
   "source": [
    "# Step-2 Pooling\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "9418205ba61cfde5099417898f3a48f8e2a67909"
   },
   "outputs": [],
   "source": [
    "# Adding a second convolutional layer\n",
    "classifier.add(Conv2D(32,(3,3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "76f00aa954e1fbe404cbb730ad74ded138c19173"
   },
   "outputs": [],
   "source": [
    "# Step-3 Flattening\n",
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "9664163b107854fc9506587964f20f9182a3d348"
   },
   "outputs": [],
   "source": [
    "# Step-4 Full connection\n",
    "classifier.add(Dense(units=128,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "b4787b0c56c0d82dd48f7ab3f7181bb35b1ce913"
   },
   "outputs": [],
   "source": [
    "classifier.add(Dense(units=1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "13db892befdbc7245d5a018967f0bc81af1c4d44"
   },
   "outputs": [],
   "source": [
    "# Compiling the CNN\n",
    "classifier.compile(optimizer= 'adam',loss='binary_crossentropy',metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "4e1c10d9c9a608bbd79b381183e22c958fe69a96"
   },
   "outputs": [],
   "source": [
    "# Fitting the CNN\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "280ecc78e74f518fe0c4dc112e38cfb93858403a"
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "e7ea4759cb5ef3e71b4c1657e189014efd0363a8"
   },
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "c0502801ce3ff5c56e92cf5239740edc6db99c83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory(\n",
    "        '../input/dataset/dataset/training_set',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "769f1014da7bd4987925b509f1e58a52151dec8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_directory(\n",
    "        '../input/dataset/dataset/test_set',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "cabd6bf36ff479b0139e47c953f2b94b02861f01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8000/8000 [==============================] - 1307s 163ms/step - loss: 0.3662 - acc: 0.8263 - val_loss: 0.5623 - val_acc: 0.8176\n",
      "Epoch 2/10\n",
      "8000/8000 [==============================] - 1331s 166ms/step - loss: 0.1085 - acc: 0.9586 - val_loss: 0.9528 - val_acc: 0.7925\n",
      "Epoch 3/10\n",
      "8000/8000 [==============================] - 1331s 166ms/step - loss: 0.0542 - acc: 0.9807 - val_loss: 1.0898 - val_acc: 0.7968\n",
      "Epoch 4/10\n",
      "8000/8000 [==============================] - 1287s 161ms/step - loss: 0.0398 - acc: 0.9864 - val_loss: 1.2373 - val_acc: 0.7935\n",
      "Epoch 5/10\n",
      "8000/8000 [==============================] - 1308s 164ms/step - loss: 0.0310 - acc: 0.9894 - val_loss: 1.3210 - val_acc: 0.7925\n",
      "Epoch 6/10\n",
      "8000/8000 [==============================] - 1330s 166ms/step - loss: 0.0271 - acc: 0.9910 - val_loss: 1.3746 - val_acc: 0.7981\n",
      "Epoch 7/10\n",
      "8000/8000 [==============================] - 1348s 168ms/step - loss: 0.0227 - acc: 0.9925 - val_loss: 1.4372 - val_acc: 0.7947\n",
      "Epoch 8/10\n",
      "8000/8000 [==============================] - 1347s 168ms/step - loss: 0.0202 - acc: 0.9934 - val_loss: 1.4770 - val_acc: 0.7955\n",
      "Epoch 9/10\n",
      "8000/8000 [==============================] - 1351s 169ms/step - loss: 0.0185 - acc: 0.9939 - val_loss: 1.4623 - val_acc: 0.8028\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 1348s 168ms/step - loss: 0.0164 - acc: 0.9946 - val_loss: 1.4827 - val_acc: 0.8107\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7fd20ba208>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit_generator(\n",
    "        training_set,\n",
    "        steps_per_epoch=8000,\n",
    "        epochs=10,\n",
    "        validation_data=test_set,\n",
    "        validation_steps=2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8ddf3498bad2e5db199ecdf472a4a6bc5711916d"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
